
Given the highly variable nature of the task, where the structure of target websites can change unpredictably and require complex adaptations to scraping logic, we determined that **prompt** engineering was the most appropriate technique for automating scraper repair. Unlike approaches such as Retrieval-Augment Generation which, like explained above, are more effective in knowledge-intensive scenarios where external factual retrieval is essential, our use case demands a more flexible and context-drive solution. The primary challenge lies in dynamically understanding and adapting to the structural changes in websites, and subsequently generating accurate and functional Kotlin code.

Prompt engineering allows us to tailor inputs to the language model with precision. By crafting structured prompts that include the failing scraper code and the modifications required to make the scraper functional again, we can guide the LLM to generate corrected code.

In summary, prompt engineering was selected for its adaptability, simplicity of integration, and ability to encode complex intent and contextual cues directly into model interactions. This makes it particularly effective for dynamic code generation in failure prone environments like web scraping. Training a model from scratch to learn scraper-specific patterns, or even fine-tuning an existing language model, would introduce significant computational and time overhead. In contrast, prompt engineering enables us to immediately leverage the capabilities of powerful foundation models without the need for additional training, making it especially well-suited for rapid prototyping and scalable production deployment.
